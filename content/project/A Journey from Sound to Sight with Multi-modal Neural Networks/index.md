---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "Sonnet to Picture: A Journey from Sound to Sight with Multi-modal Neural Networks"
summary: In this intriguing course project, we introduce a multi-modal neural network architecture that's capable of generating images from audio descriptions. By using pretrained unimodal networks and training an intermediate alignment network, we managed to navigate around the unavailability of paired audio and image datasets. We experimented with a composite loss function and measured performance through multiple metrics, ultimately yielding a promising model that can generate images from spoken descriptions. Despite the limitations identified, the project serves as a stepping stone towards the potential improvement of human-machine interactions and computer-aided design.
authors: ["Yutian Lei", "Hongkai Jiang", "Gaurav Satyanath", "Soyong Shin", "Louise Xie"]
tags: ["Neural Networks", "Image Generation", "Audio", "Multi-modal Learning", "Deep Learning"]
categories: ["Course Project"]
date: 2022-05-01

# Optional external URL for project (replaces project detail page).
external_link: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---